{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e335525",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "270e0d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/9mdr6prj6sl8b2bz2kjm1vw80000gn/T/ipykernel_29281/3205347933.py:12: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('sample_citibike_2023.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   ride_id             1000000 non-null  object \n",
      " 1   rideable_type       1000000 non-null  object \n",
      " 2   started_at          1000000 non-null  object \n",
      " 3   ended_at            1000000 non-null  object \n",
      " 4   start_station_name  999459 non-null   object \n",
      " 5   start_station_id    999459 non-null   object \n",
      " 6   end_station_name    997192 non-null   object \n",
      " 7   end_station_id      997192 non-null   object \n",
      " 8   start_lat           1000000 non-null  float64\n",
      " 9   start_lng           1000000 non-null  float64\n",
      " 10  end_lat             999287 non-null   float64\n",
      " 11  end_lng             999287 non-null   float64\n",
      " 12  member_casual       1000000 non-null  object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 99.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('sample_citibike_2023.csv')\n",
    "\n",
    "# Drop the first column Index\n",
    "df = df.iloc[:, 1:]\n",
    "\n",
    "# Check data types and non-null values\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad67392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'started_at' and 'ended_at' to datetime\n",
    "df['started_at'] = pd.to_datetime(df['started_at'])\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'])\n",
    "\n",
    "# Calculate trip duration in minutes\n",
    "df['trip_duration'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60\n",
    "\n",
    "# Remove rows with negative or zero durations\n",
    "df = df[df['trip_duration'] > 0]\n",
    "\n",
    "# Fill missing categorical values\n",
    "df['start_station_name'].fillna('Unknown', inplace=True)\n",
    "df['end_station_name'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Remove outliers using the IQR method\n",
    "Q1 = df['trip_duration'].quantile(0.25)\n",
    "Q3 = df['trip_duration'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df[(df['trip_duration'] >= lower_bound) & (df['trip_duration'] <= upper_bound)]\n",
    "\n",
    "# Feature engineering\n",
    "df['hour'] = df['started_at'].dt.hour\n",
    "df['day_of_week'] = df['started_at'].dt.dayofweek\n",
    "df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['start_station_name_encoded'] = label_encoder.fit_transform(df['start_station_name'])\n",
    "df['end_station_name_encoded'] = label_encoder.fit_transform(df['end_station_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca428471",
   "metadata": {},
   "source": [
    "## 2. Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b460eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = [\n",
    "    'start_lat', 'start_lng', 'end_lat', 'end_lng',\n",
    "    'hour', 'day_of_week', 'is_weekend',\n",
    "    'start_station_name_encoded', 'end_station_name_encoded'\n",
    "]\n",
    "target = 'trip_duration'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de81ed74",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb28ee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best Hyperparameters: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],        \n",
    "    'max_depth': [10, 20, None],          \n",
    "    'min_samples_split': [2, 5],           \n",
    "    'min_samples_leaf': [1, 2],           \n",
    "    'max_features': ['sqrt', 'log2'],    \n",
    "    'bootstrap': [True]             \n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestRegressor(random_state=123)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,          # Test 10 parameter combinations\n",
    "    cv=2,               # 2-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',  # Minimize mean squared error\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1           # Use all available cores\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f562ec8",
   "metadata": {},
   "source": [
    "## 4. Evaluate the Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fca29bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (Tuned Model): 4.66569918151125\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  56.8s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  59.3s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  56.9s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  59.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  28.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  30.7s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  28.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  30.4s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time= 4.4min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time= 4.4min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  28.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time= 4.2min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  28.3s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time= 4.2min\n"
     ]
    }
   ],
   "source": [
    "# Predict using the best model\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "rmse_tuned = np.sqrt(mean_squared_error(y_test, y_pred_tuned))\n",
    "print(f'Root Mean Squared Error (Tuned Model): {rmse_tuned}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c0a2cc",
   "metadata": {},
   "source": [
    "Baseline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e4b59d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 7.320116425746809\n"
     ]
    }
   ],
   "source": [
    "baseline_pred = [y_train.mean()] * len(y_test)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_test, baseline_pred))\n",
    "print(f'Baseline RMSE: {baseline_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c552ca2f",
   "metadata": {},
   "source": [
    "R² Score (Coefficient of Determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7007de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.5937458253159373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred_tuned)\n",
    "print(f'R² Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a7e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
